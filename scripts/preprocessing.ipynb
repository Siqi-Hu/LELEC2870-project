{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load the packages"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Data processing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Machine learning packages\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MultiLabelBinarizer, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import torch\n",
    "\n",
    "# Visualization packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Others\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Read the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "X1 = pd.read_csv(\"X1.csv\")\n",
    "Y1 = pd.read_csv(\"Y1.csv\", header=None, names=['revenue '])\n",
    "# X2 = pd.read_csv(\"X2.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 1: Data Cleaning (columns drop off and missing value processing)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def data_cleaning_process(df):\n",
    "    \"\"\"\n",
    "    This function will drop columns, like \"Unnamed: 0\", \"title\", \"img_url\", \"description\" from the dataset, and replace the missing value in `runtime` column with a median value, and replace the missing value in `genres` with \"Others\".\n",
    "    :param df: A dataframe (X1 or X2)\n",
    "    :return: A new cleaned dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    new_df = df.copy()\n",
    "    # missing value for runtime: replace \"\\\\N\" with median value\n",
    "    median_runtime = np.median(new_df.loc[new_df['runtime'] != '\\\\N', 'runtime'].astype(np.int64))\n",
    "    new_df['runtime'] = np.where(new_df['runtime'] == '\\\\N', median_runtime, new_df['runtime']).astype(np.int64)\n",
    "\n",
    "    # missing value for genres: replace \"\\\\N\" with \"Others\"\n",
    "    new_df.loc[new_df['genres'] == \"\\\\N\", \"genres\"] = \"Others\"\n",
    "\n",
    "    # drop \"Unnamed: 0\", \"title\", \"img_url\", \"description\"\n",
    "    new_df = new_df.drop([\"Unnamed: 0\", \"title\", \"img_url\", \"description\"], axis=1)\n",
    "\n",
    "    return new_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# X1_cleaned = data_cleaning_process(X1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2: Data Type Split (Numerical, Categorical, Embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def data_type_split(df):\n",
    "    \"\"\"\n",
    "    This function will split the whole dataset into different sub dataset according to the data types of the columns\n",
    "    :param df: A dataframe\n",
    "    :return: three datadrames, which are numerical, categorical, embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    new_df = df.copy()\n",
    "    numeric_features = new_df.select_dtypes(include=\"number\").columns.tolist()\n",
    "    non_numeric_features = new_df.select_dtypes(exclude=\"number\").columns.tolist()\n",
    "    embedding_features = ['img_embeddings', 'text_embeddings']\n",
    "    numeric_features.remove('is_adult')\n",
    "    categorical_features = non_numeric_features.copy()\n",
    "    [categorical_features.remove(col) for col in embedding_features]\n",
    "    categorical_features.append('is_adult')\n",
    "    return new_df.loc[:, numeric_features], new_df.loc[:, categorical_features], new_df.loc[:, embedding_features]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# df_num, df_cat, df_emb = data_type_split(X1_cleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# df_num"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 3: Categorical Columns Processing (Genres --> multilable binary type, Studio --> studio_frequency)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "dict_cat_freq = torch.load(\"studio_freq\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def categorical_process(df):\n",
    "    \"\"\"\n",
    "    This function will process on `genres` and `studio` columns.\n",
    "    `genres` will be transformed to multilabel binary variables;\n",
    "    `studio` will be transformed to a frequency type.\n",
    "    :param df: A categorical datframe\n",
    "    :return: A new dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    new_df = df.copy()\n",
    "\n",
    "    # processing on `genres` column\n",
    "    new_df['genres_split'] = new_df['genres'].apply(lambda x: x.split(\",\"))\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    genere_encoder_df = pd.DataFrame(mlb.fit_transform(new_df['genres_split']))\n",
    "    genere_encoder_df.columns = mlb.classes_.tolist()\n",
    "\n",
    "    # processing on `studio` column\n",
    "    studio_freq_df = pd.DataFrame(new_df['studio'].apply(lambda x: dict_cat_freq[x] if x in dict_cat_freq.keys() else min(dict_cat_freq.values())))\n",
    "    studio_freq_df.columns = ['studio_freq']\n",
    "\n",
    "\n",
    "    processed_cat_df = pd.concat([genere_encoder_df, studio_freq_df, new_df['is_adult']], axis=1)\n",
    "\n",
    "    return processed_cat_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# categorical_process(df_cat)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 4: Embedding Column Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def listToDF(df, column_name):\n",
    "\n",
    "    new_df = []\n",
    "    for row in df[column_name]:\n",
    "        ls = []\n",
    "        row = eval(row)\n",
    "        for each in row:\n",
    "            ls.append(each)\n",
    "        new_df.append(ls)\n",
    "\n",
    "    new_df = pd.DataFrame(new_df)\n",
    "\n",
    "    return new_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def embedding_process(df):\n",
    "    new_df = df.copy()\n",
    "\n",
    "    # image embeddings\n",
    "    img_emb_df = listToDF(new_df, 'img_embeddings')\n",
    "    text_emb_df = listToDF(new_df, 'text_embeddings')\n",
    "\n",
    "    processed_emb_df = pd.concat([img_emb_df, text_emb_df], axis=1)\n",
    "    return processed_emb_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# embedding_process(X1.loc[:, ['img_embeddings', 'text_embeddings']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 5: Combine Everything"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def data_combine(df_num, df_cat, df_emb):\n",
    "    new_df = pd.concat([df_num, df_cat, df_emb], axis=1)\n",
    "    return new_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# df_processed = data_combine(df_num, categorical_process(df_cat), df_emb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# df_processed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 6: Normalization and Standarization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def data_scaling(df):\n",
    "    \"\"\"\n",
    "    This function will process on the numercial columns.\n",
    "    For `ratings`, we will use normalization\n",
    "    For the other columns, we will use standardization\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_X = df.copy().to_numpy()\n",
    "\n",
    "    # df_norm = new_df[\"ratings\"]\n",
    "    # df_stad = new_df.iloc[:, 1:]\n",
    "    scaler_norm = MinMaxScaler().fit(new_X[:, 0].reshape([-1, 1]))\n",
    "    scaler_stad = StandardScaler().fit(new_X[:, 1:5])\n",
    "    new_X[:, 0] = scaler_norm.transform(new_X[:, 0].reshape([-1, 1])).ravel()\n",
    "    new_X[:, 1:5] = scaler_stad.transform(new_X[:, 1:5])\n",
    "\n",
    "    return new_X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# data_scaling(df_processed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Construct Data Engineering Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def DataEngineering(df):\n",
    "    df_cleaned = data_cleaning_process(df)\n",
    "    df_num, df_cat, df_emb = data_type_split(df_cleaned)\n",
    "    df_cat_processed = categorical_process(df_cat)\n",
    "    df_emb_processed = embedding_process(df_emb)\n",
    "    df_processed = data_combine(df_num, df_cat_processed, df_emb_processed)\n",
    "    X_ready = data_scaling(df_processed)\n",
    "\n",
    "    return X_ready"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "preprocess_transformer = FunctionTransformer(DataEngineering)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "p1 = Pipeline([\n",
    "    ('Preprocessor', preprocess_transformer)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "X1_ready = p1.fit_transform(X1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.60674157,  0.80919972,  1.11135356, ...,  0.99988544,\n        -0.49546754,  0.95906293],\n       [ 0.76404494, -0.27177631, -0.07338902, ...,  0.9998001 ,\n        -0.5089115 ,  0.9546743 ],\n       [ 0.53932584, -0.25625834, -1.59662947, ...,  0.9999524 ,\n        -0.45857945,  0.9761356 ],\n       ...,\n       [ 0.73033708, -0.27150875,  0.34973333, ...,  0.99994576,\n        -0.3214418 ,  0.97996914],\n       [ 0.71910112,  0.04658617,  0.77285568, ...,  0.9999413 ,\n        -0.3090013 ,  0.9727902 ],\n       [ 0.33707865, -0.24519569,  0.26510886, ...,  0.9998354 ,\n        -0.75486994,  0.9661582 ]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_ready"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

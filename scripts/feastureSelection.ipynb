{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load the packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data processing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Machine learning packages\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_val_score, KFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MultiLabelBinarizer, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_selection import SequentialFeatureSelector, RFE\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "\n",
    "\n",
    "# Visualization packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Others\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Read the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X1 = torch.load('X1_ready')\n",
    "Y1 = pd.read_csv(\"Y1.csv\", header=None, names=['revenue ']).values.ravel()\n",
    "X2 = torch.load('X2_ready')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Feature Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.0 Give the column names to the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def renamingDataset(X):\n",
    "    new_X = X.copy()\n",
    "    new_df = pd.DataFrame(new_X)\n",
    "    num_col_names = ['ratings', 'n_votes', 'production_year', 'runtime', 'release_year']\n",
    "    cat_col_names = ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime',\n",
    "       'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'Game-Show',\n",
    "       'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News', 'Others',\n",
    "       'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Thriller', 'War',\n",
    "       'Western', 'studio_freq', 'is_adult']\n",
    "    img_emb_names = []\n",
    "    for i in range(2048):\n",
    "        img_emb_names.append(\"img_emb_\" + str(i))\n",
    "\n",
    "    text_emb_names = []\n",
    "    for i in range(768):\n",
    "        text_emb_names.append(\"text_emb_\" + str(i))\n",
    "\n",
    "    all_col_names = num_col_names + cat_col_names + img_emb_names + text_emb_names\n",
    "\n",
    "    new_df.columns = all_col_names\n",
    "\n",
    "    return new_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "renamed_df_ready = renamingDataset(X1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def divideDataset(df):\n",
    "    new_df = df.copy()\n",
    "\n",
    "    non_emb_df = new_df.iloc[:, :34]\n",
    "    img_emb_df = new_df.iloc[:, 34:2082]\n",
    "    text_emb_df = new_df.iloc[:, 2082:]\n",
    "\n",
    "    return non_emb_df, img_emb_df, text_emb_df # pd.dataframe type"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "       ratings   n_votes  production_year   runtime  release_year  Action  \\\n0     0.606742  0.809200         1.111354  0.398460      0.933839     0.0   \n1     0.764045 -0.271776        -0.073389  0.079814      1.366959     1.0   \n2     0.539326 -0.256258        -1.596629  1.099479     -2.531122     0.0   \n3     0.617978 -0.215474        -0.242638  0.398460     -0.798642     0.0   \n4     0.337079 -0.265518        -1.258132  0.494053     -2.098002     0.0   \n...        ...       ...              ...       ...           ...     ...   \n3535  0.584270 -0.260586         0.011235  0.047950     -0.257241     0.0   \n3536  0.775281 -0.246429        -3.035245 -2.150702      1.691799     0.0   \n3537  0.730337 -0.271509         0.349733 -1.545276     -0.148961     0.0   \n3538  0.719101  0.046586         0.772856  0.175408      0.500719     0.0   \n3539  0.337079 -0.245196         0.265109  0.016085     -0.148961     0.0   \n\n      Adventure  Animation  Biography  Comedy  ...  Reality-TV  Romance  \\\n0           1.0        0.0        0.0     1.0  ...         0.0      0.0   \n1           0.0        0.0        0.0     0.0  ...         0.0      0.0   \n2           0.0        0.0        0.0     0.0  ...         0.0      0.0   \n3           0.0        0.0        1.0     0.0  ...         0.0      0.0   \n4           0.0        0.0        0.0     0.0  ...         0.0      0.0   \n...         ...        ...        ...     ...  ...         ...      ...   \n3535        0.0        0.0        0.0     1.0  ...         0.0      0.0   \n3536        0.0        0.0        0.0     0.0  ...         0.0      0.0   \n3537        0.0        0.0        0.0     0.0  ...         0.0      1.0   \n3538        0.0        0.0        0.0     0.0  ...         0.0      0.0   \n3539        0.0        0.0        0.0     1.0  ...         0.0      0.0   \n\n      Sci-Fi  Short  Sport  Thriller  War  Western  studio_freq  is_adult  \n0        0.0    0.0    0.0       0.0  0.0      0.0     0.001695       0.0  \n1        0.0    0.0    0.0       0.0  0.0      0.0     0.000565       0.0  \n2        0.0    0.0    1.0       0.0  0.0      0.0     0.025141       0.0  \n3        0.0    0.0    1.0       0.0  0.0      0.0     0.016949       0.0  \n4        0.0    0.0    1.0       0.0  0.0      0.0     0.025141       0.0  \n...      ...    ...    ...       ...  ...      ...          ...       ...  \n3535     0.0    0.0    0.0       0.0  0.0      0.0     0.002825       0.0  \n3536     0.0    0.0    0.0       0.0  0.0      0.0     0.001130       0.0  \n3537     0.0    0.0    0.0       0.0  0.0      0.0     0.005650       0.0  \n3538     0.0    0.0    0.0       0.0  0.0      0.0     0.026836       0.0  \n3539     0.0    0.0    1.0       0.0  0.0      0.0     0.000282       0.0  \n\n[3540 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ratings</th>\n      <th>n_votes</th>\n      <th>production_year</th>\n      <th>runtime</th>\n      <th>release_year</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Biography</th>\n      <th>Comedy</th>\n      <th>...</th>\n      <th>Reality-TV</th>\n      <th>Romance</th>\n      <th>Sci-Fi</th>\n      <th>Short</th>\n      <th>Sport</th>\n      <th>Thriller</th>\n      <th>War</th>\n      <th>Western</th>\n      <th>studio_freq</th>\n      <th>is_adult</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.606742</td>\n      <td>0.809200</td>\n      <td>1.111354</td>\n      <td>0.398460</td>\n      <td>0.933839</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.001695</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.764045</td>\n      <td>-0.271776</td>\n      <td>-0.073389</td>\n      <td>0.079814</td>\n      <td>1.366959</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000565</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.539326</td>\n      <td>-0.256258</td>\n      <td>-1.596629</td>\n      <td>1.099479</td>\n      <td>-2.531122</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.025141</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.617978</td>\n      <td>-0.215474</td>\n      <td>-0.242638</td>\n      <td>0.398460</td>\n      <td>-0.798642</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.016949</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.337079</td>\n      <td>-0.265518</td>\n      <td>-1.258132</td>\n      <td>0.494053</td>\n      <td>-2.098002</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.025141</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3535</th>\n      <td>0.584270</td>\n      <td>-0.260586</td>\n      <td>0.011235</td>\n      <td>0.047950</td>\n      <td>-0.257241</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.002825</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3536</th>\n      <td>0.775281</td>\n      <td>-0.246429</td>\n      <td>-3.035245</td>\n      <td>-2.150702</td>\n      <td>1.691799</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.001130</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3537</th>\n      <td>0.730337</td>\n      <td>-0.271509</td>\n      <td>0.349733</td>\n      <td>-1.545276</td>\n      <td>-0.148961</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.005650</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3538</th>\n      <td>0.719101</td>\n      <td>0.046586</td>\n      <td>0.772856</td>\n      <td>0.175408</td>\n      <td>0.500719</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.026836</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3539</th>\n      <td>0.337079</td>\n      <td>-0.245196</td>\n      <td>0.265109</td>\n      <td>0.016085</td>\n      <td>-0.148961</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000282</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3540 rows × 34 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_emb_df, img_emb_df, text_emb_df = divideDataset(renamed_df_ready)\n",
    "non_emb_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 DR on Embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "scaler_emb = MinMaxScaler()\n",
    "emb_df_scaled = scaler_emb.fit_transform(pd.concat([img_emb_df, text_emb_df], axis=1))\n",
    "pca_emb = PCA(n_components=0.9)\n",
    "pca_emb.fit(emb_df_scaled)\n",
    "\n",
    "def DRembeddings(img_emb_df, text_emb_df, n_components=0.95):\n",
    "\n",
    "    # scale the data to the range between 0 and 1 before using PCA\n",
    "    # scaler_emb = MinMaxScaler()\n",
    "    # img_emb_df_scaled = scaler_emb.fit_transform(img_emb_df)\n",
    "    # text_emb_df_scaled = scaler_emb.fit_transform(text_emb_df)\n",
    "    emb_df_scaled = scaler_emb.fit_transform(pd.concat([img_emb_df, text_emb_df], axis=1))\n",
    "\n",
    "    # pca_emb = PCA(n_components=n_components)\n",
    "    # df_reduced_emb = pd.DataFrame(pca_emb.fit_transform(emb_df_scaled))\n",
    "    df_reduced_emb = pd.DataFrame(pca_emb.transform(emb_df_scaled))\n",
    "\n",
    "    emb_col_names = []\n",
    "    for i in range(df_reduced_emb.shape[1]):\n",
    "        emb_col_names.append(\"emb_\" + str(i))\n",
    "\n",
    "    df_reduced_emb.columns = emb_col_names\n",
    "\n",
    "    return df_reduced_emb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "         emb_0     emb_1     emb_2     emb_3     emb_4     emb_5     emb_6  \\\n0     1.054328 -2.153237 -0.802997 -0.248707  1.349493 -0.057840  1.314132   \n1     2.129040 -1.483597  0.043256  0.420362  0.764355 -0.197161 -2.482356   \n2    -0.875198  1.225310 -0.543729 -1.675668 -0.747023 -0.841552  0.549715   \n3    -2.737351 -0.962277 -0.147203  0.202019  0.383081  0.646871  1.802819   \n4    -0.188856 -1.475641  1.705273  0.440138  0.412238 -1.173195 -0.601143   \n...        ...       ...       ...       ...       ...       ...       ...   \n3535  2.200888 -1.601251 -1.428959 -1.419945 -0.136471 -0.784107  0.130939   \n3536  2.292233  0.514620 -2.268296  1.002200 -0.883624 -0.801217 -0.707837   \n3537 -0.875170  0.782112 -1.783827 -1.313507  0.580249 -0.994133 -0.276110   \n3538 -2.001723 -1.145958  1.331780 -1.073421  0.935715 -1.775468 -0.476440   \n3539  1.670565 -1.675665  1.313650 -0.578221 -1.393528 -0.122406  0.134769   \n\n         emb_7     emb_8     emb_9  ...   emb_189   emb_190   emb_191  \\\n0    -0.675291  1.171299  0.436517  ... -0.020153 -0.015117  0.237029   \n1     0.903683 -1.484753 -0.512926  ... -0.194736  0.081447  0.099483   \n2    -1.524902 -0.489789  0.147765  ...  0.092746  0.026760  0.241836   \n3     0.555741  1.016410  0.509889  ...  0.222160 -0.061716  0.269019   \n4    -0.155727 -0.484766 -0.416415  ... -0.053639 -0.288431  0.096173   \n...        ...       ...       ...  ...       ...       ...       ...   \n3535 -0.890358  0.586813 -0.254475  ...  0.090543 -0.110694  0.100748   \n3536  0.342407 -0.305779 -0.881682  ... -0.031045  0.055816  0.341487   \n3537 -0.226078  0.496469  0.417320  ... -0.156029  0.231721 -0.045153   \n3538  1.169051  2.360350  0.496899  ...  0.156725 -0.109072  0.018352   \n3539  0.395101  0.044700 -0.028331  ...  0.108369  0.112168 -0.168308   \n\n       emb_192   emb_193   emb_194   emb_195   emb_196   emb_197   emb_198  \n0    -0.028050 -0.023873  0.079219 -0.031364 -0.071154 -0.091889 -0.235259  \n1    -0.115929  0.107830  0.129517 -0.144803 -0.000834 -0.156755  0.159004  \n2     0.224205  0.007772  0.136998  0.067925 -0.050262  0.116298  0.057964  \n3    -0.029332  0.159303  0.049171  0.240762 -0.297771 -0.147129  0.116596  \n4    -0.151598  0.179133  0.025855  0.221040  0.155626 -0.151701 -0.016146  \n...        ...       ...       ...       ...       ...       ...       ...  \n3535  0.411141 -0.191849  0.070196 -0.251843  0.062231  0.173676 -0.353208  \n3536 -0.143810  0.275008  0.035487 -0.250839 -0.502362 -0.521410  0.010129  \n3537  0.440696 -0.110274  0.025682 -0.034410 -0.120474  0.086602 -0.152570  \n3538 -0.131649 -0.065725 -0.041340 -0.030564 -0.380415  0.054779 -0.108390  \n3539  0.181592  0.101270 -0.011321 -0.133576  0.074869  0.236674  0.020680  \n\n[3540 rows x 199 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emb_0</th>\n      <th>emb_1</th>\n      <th>emb_2</th>\n      <th>emb_3</th>\n      <th>emb_4</th>\n      <th>emb_5</th>\n      <th>emb_6</th>\n      <th>emb_7</th>\n      <th>emb_8</th>\n      <th>emb_9</th>\n      <th>...</th>\n      <th>emb_189</th>\n      <th>emb_190</th>\n      <th>emb_191</th>\n      <th>emb_192</th>\n      <th>emb_193</th>\n      <th>emb_194</th>\n      <th>emb_195</th>\n      <th>emb_196</th>\n      <th>emb_197</th>\n      <th>emb_198</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.054328</td>\n      <td>-2.153237</td>\n      <td>-0.802997</td>\n      <td>-0.248707</td>\n      <td>1.349493</td>\n      <td>-0.057840</td>\n      <td>1.314132</td>\n      <td>-0.675291</td>\n      <td>1.171299</td>\n      <td>0.436517</td>\n      <td>...</td>\n      <td>-0.020153</td>\n      <td>-0.015117</td>\n      <td>0.237029</td>\n      <td>-0.028050</td>\n      <td>-0.023873</td>\n      <td>0.079219</td>\n      <td>-0.031364</td>\n      <td>-0.071154</td>\n      <td>-0.091889</td>\n      <td>-0.235259</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.129040</td>\n      <td>-1.483597</td>\n      <td>0.043256</td>\n      <td>0.420362</td>\n      <td>0.764355</td>\n      <td>-0.197161</td>\n      <td>-2.482356</td>\n      <td>0.903683</td>\n      <td>-1.484753</td>\n      <td>-0.512926</td>\n      <td>...</td>\n      <td>-0.194736</td>\n      <td>0.081447</td>\n      <td>0.099483</td>\n      <td>-0.115929</td>\n      <td>0.107830</td>\n      <td>0.129517</td>\n      <td>-0.144803</td>\n      <td>-0.000834</td>\n      <td>-0.156755</td>\n      <td>0.159004</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.875198</td>\n      <td>1.225310</td>\n      <td>-0.543729</td>\n      <td>-1.675668</td>\n      <td>-0.747023</td>\n      <td>-0.841552</td>\n      <td>0.549715</td>\n      <td>-1.524902</td>\n      <td>-0.489789</td>\n      <td>0.147765</td>\n      <td>...</td>\n      <td>0.092746</td>\n      <td>0.026760</td>\n      <td>0.241836</td>\n      <td>0.224205</td>\n      <td>0.007772</td>\n      <td>0.136998</td>\n      <td>0.067925</td>\n      <td>-0.050262</td>\n      <td>0.116298</td>\n      <td>0.057964</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-2.737351</td>\n      <td>-0.962277</td>\n      <td>-0.147203</td>\n      <td>0.202019</td>\n      <td>0.383081</td>\n      <td>0.646871</td>\n      <td>1.802819</td>\n      <td>0.555741</td>\n      <td>1.016410</td>\n      <td>0.509889</td>\n      <td>...</td>\n      <td>0.222160</td>\n      <td>-0.061716</td>\n      <td>0.269019</td>\n      <td>-0.029332</td>\n      <td>0.159303</td>\n      <td>0.049171</td>\n      <td>0.240762</td>\n      <td>-0.297771</td>\n      <td>-0.147129</td>\n      <td>0.116596</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.188856</td>\n      <td>-1.475641</td>\n      <td>1.705273</td>\n      <td>0.440138</td>\n      <td>0.412238</td>\n      <td>-1.173195</td>\n      <td>-0.601143</td>\n      <td>-0.155727</td>\n      <td>-0.484766</td>\n      <td>-0.416415</td>\n      <td>...</td>\n      <td>-0.053639</td>\n      <td>-0.288431</td>\n      <td>0.096173</td>\n      <td>-0.151598</td>\n      <td>0.179133</td>\n      <td>0.025855</td>\n      <td>0.221040</td>\n      <td>0.155626</td>\n      <td>-0.151701</td>\n      <td>-0.016146</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3535</th>\n      <td>2.200888</td>\n      <td>-1.601251</td>\n      <td>-1.428959</td>\n      <td>-1.419945</td>\n      <td>-0.136471</td>\n      <td>-0.784107</td>\n      <td>0.130939</td>\n      <td>-0.890358</td>\n      <td>0.586813</td>\n      <td>-0.254475</td>\n      <td>...</td>\n      <td>0.090543</td>\n      <td>-0.110694</td>\n      <td>0.100748</td>\n      <td>0.411141</td>\n      <td>-0.191849</td>\n      <td>0.070196</td>\n      <td>-0.251843</td>\n      <td>0.062231</td>\n      <td>0.173676</td>\n      <td>-0.353208</td>\n    </tr>\n    <tr>\n      <th>3536</th>\n      <td>2.292233</td>\n      <td>0.514620</td>\n      <td>-2.268296</td>\n      <td>1.002200</td>\n      <td>-0.883624</td>\n      <td>-0.801217</td>\n      <td>-0.707837</td>\n      <td>0.342407</td>\n      <td>-0.305779</td>\n      <td>-0.881682</td>\n      <td>...</td>\n      <td>-0.031045</td>\n      <td>0.055816</td>\n      <td>0.341487</td>\n      <td>-0.143810</td>\n      <td>0.275008</td>\n      <td>0.035487</td>\n      <td>-0.250839</td>\n      <td>-0.502362</td>\n      <td>-0.521410</td>\n      <td>0.010129</td>\n    </tr>\n    <tr>\n      <th>3537</th>\n      <td>-0.875170</td>\n      <td>0.782112</td>\n      <td>-1.783827</td>\n      <td>-1.313507</td>\n      <td>0.580249</td>\n      <td>-0.994133</td>\n      <td>-0.276110</td>\n      <td>-0.226078</td>\n      <td>0.496469</td>\n      <td>0.417320</td>\n      <td>...</td>\n      <td>-0.156029</td>\n      <td>0.231721</td>\n      <td>-0.045153</td>\n      <td>0.440696</td>\n      <td>-0.110274</td>\n      <td>0.025682</td>\n      <td>-0.034410</td>\n      <td>-0.120474</td>\n      <td>0.086602</td>\n      <td>-0.152570</td>\n    </tr>\n    <tr>\n      <th>3538</th>\n      <td>-2.001723</td>\n      <td>-1.145958</td>\n      <td>1.331780</td>\n      <td>-1.073421</td>\n      <td>0.935715</td>\n      <td>-1.775468</td>\n      <td>-0.476440</td>\n      <td>1.169051</td>\n      <td>2.360350</td>\n      <td>0.496899</td>\n      <td>...</td>\n      <td>0.156725</td>\n      <td>-0.109072</td>\n      <td>0.018352</td>\n      <td>-0.131649</td>\n      <td>-0.065725</td>\n      <td>-0.041340</td>\n      <td>-0.030564</td>\n      <td>-0.380415</td>\n      <td>0.054779</td>\n      <td>-0.108390</td>\n    </tr>\n    <tr>\n      <th>3539</th>\n      <td>1.670565</td>\n      <td>-1.675665</td>\n      <td>1.313650</td>\n      <td>-0.578221</td>\n      <td>-1.393528</td>\n      <td>-0.122406</td>\n      <td>0.134769</td>\n      <td>0.395101</td>\n      <td>0.044700</td>\n      <td>-0.028331</td>\n      <td>...</td>\n      <td>0.108369</td>\n      <td>0.112168</td>\n      <td>-0.168308</td>\n      <td>0.181592</td>\n      <td>0.101270</td>\n      <td>-0.011321</td>\n      <td>-0.133576</td>\n      <td>0.074869</td>\n      <td>0.236674</td>\n      <td>0.020680</td>\n    </tr>\n  </tbody>\n</table>\n<p>3540 rows × 199 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced_emb = DRembeddings(img_emb_df, text_emb_df, n_components=0.9)\n",
    "df_reduced_emb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Combine non_emb with reduced_emb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def combineNonReducedEmb(non_em_df, reduced_emb_df):\n",
    "    DR_df = pd.concat([non_em_df, reduced_emb_df], axis=1)\n",
    "    return DR_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "       ratings   n_votes  production_year   runtime  release_year  Action  \\\n0     0.606742  0.809200         1.111354  0.398460      0.933839     0.0   \n1     0.764045 -0.271776        -0.073389  0.079814      1.366959     1.0   \n2     0.539326 -0.256258        -1.596629  1.099479     -2.531122     0.0   \n3     0.617978 -0.215474        -0.242638  0.398460     -0.798642     0.0   \n4     0.337079 -0.265518        -1.258132  0.494053     -2.098002     0.0   \n...        ...       ...              ...       ...           ...     ...   \n3535  0.584270 -0.260586         0.011235  0.047950     -0.257241     0.0   \n3536  0.775281 -0.246429        -3.035245 -2.150702      1.691799     0.0   \n3537  0.730337 -0.271509         0.349733 -1.545276     -0.148961     0.0   \n3538  0.719101  0.046586         0.772856  0.175408      0.500719     0.0   \n3539  0.337079 -0.245196         0.265109  0.016085     -0.148961     0.0   \n\n      Adventure  Animation  Biography  Comedy  ...   emb_189   emb_190  \\\n0           1.0        0.0        0.0     1.0  ... -0.020153 -0.015117   \n1           0.0        0.0        0.0     0.0  ... -0.194736  0.081447   \n2           0.0        0.0        0.0     0.0  ...  0.092746  0.026760   \n3           0.0        0.0        1.0     0.0  ...  0.222160 -0.061716   \n4           0.0        0.0        0.0     0.0  ... -0.053639 -0.288431   \n...         ...        ...        ...     ...  ...       ...       ...   \n3535        0.0        0.0        0.0     1.0  ...  0.090543 -0.110694   \n3536        0.0        0.0        0.0     0.0  ... -0.031045  0.055816   \n3537        0.0        0.0        0.0     0.0  ... -0.156029  0.231721   \n3538        0.0        0.0        0.0     0.0  ...  0.156725 -0.109072   \n3539        0.0        0.0        0.0     1.0  ...  0.108369  0.112168   \n\n       emb_191   emb_192   emb_193   emb_194   emb_195   emb_196   emb_197  \\\n0     0.237029 -0.028050 -0.023873  0.079219 -0.031364 -0.071154 -0.091889   \n1     0.099483 -0.115929  0.107830  0.129517 -0.144803 -0.000834 -0.156755   \n2     0.241836  0.224205  0.007772  0.136998  0.067925 -0.050262  0.116298   \n3     0.269019 -0.029332  0.159303  0.049171  0.240762 -0.297771 -0.147129   \n4     0.096173 -0.151598  0.179133  0.025855  0.221040  0.155626 -0.151701   \n...        ...       ...       ...       ...       ...       ...       ...   \n3535  0.100748  0.411141 -0.191849  0.070196 -0.251843  0.062231  0.173676   \n3536  0.341487 -0.143810  0.275008  0.035487 -0.250839 -0.502362 -0.521410   \n3537 -0.045153  0.440696 -0.110274  0.025682 -0.034410 -0.120474  0.086602   \n3538  0.018352 -0.131649 -0.065725 -0.041340 -0.030564 -0.380415  0.054779   \n3539 -0.168308  0.181592  0.101270 -0.011321 -0.133576  0.074869  0.236674   \n\n       emb_198  \n0    -0.235259  \n1     0.159004  \n2     0.057964  \n3     0.116596  \n4    -0.016146  \n...        ...  \n3535 -0.353208  \n3536  0.010129  \n3537 -0.152570  \n3538 -0.108390  \n3539  0.020680  \n\n[3540 rows x 233 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ratings</th>\n      <th>n_votes</th>\n      <th>production_year</th>\n      <th>runtime</th>\n      <th>release_year</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Biography</th>\n      <th>Comedy</th>\n      <th>...</th>\n      <th>emb_189</th>\n      <th>emb_190</th>\n      <th>emb_191</th>\n      <th>emb_192</th>\n      <th>emb_193</th>\n      <th>emb_194</th>\n      <th>emb_195</th>\n      <th>emb_196</th>\n      <th>emb_197</th>\n      <th>emb_198</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.606742</td>\n      <td>0.809200</td>\n      <td>1.111354</td>\n      <td>0.398460</td>\n      <td>0.933839</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>-0.020153</td>\n      <td>-0.015117</td>\n      <td>0.237029</td>\n      <td>-0.028050</td>\n      <td>-0.023873</td>\n      <td>0.079219</td>\n      <td>-0.031364</td>\n      <td>-0.071154</td>\n      <td>-0.091889</td>\n      <td>-0.235259</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.764045</td>\n      <td>-0.271776</td>\n      <td>-0.073389</td>\n      <td>0.079814</td>\n      <td>1.366959</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.194736</td>\n      <td>0.081447</td>\n      <td>0.099483</td>\n      <td>-0.115929</td>\n      <td>0.107830</td>\n      <td>0.129517</td>\n      <td>-0.144803</td>\n      <td>-0.000834</td>\n      <td>-0.156755</td>\n      <td>0.159004</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.539326</td>\n      <td>-0.256258</td>\n      <td>-1.596629</td>\n      <td>1.099479</td>\n      <td>-2.531122</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.092746</td>\n      <td>0.026760</td>\n      <td>0.241836</td>\n      <td>0.224205</td>\n      <td>0.007772</td>\n      <td>0.136998</td>\n      <td>0.067925</td>\n      <td>-0.050262</td>\n      <td>0.116298</td>\n      <td>0.057964</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.617978</td>\n      <td>-0.215474</td>\n      <td>-0.242638</td>\n      <td>0.398460</td>\n      <td>-0.798642</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.222160</td>\n      <td>-0.061716</td>\n      <td>0.269019</td>\n      <td>-0.029332</td>\n      <td>0.159303</td>\n      <td>0.049171</td>\n      <td>0.240762</td>\n      <td>-0.297771</td>\n      <td>-0.147129</td>\n      <td>0.116596</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.337079</td>\n      <td>-0.265518</td>\n      <td>-1.258132</td>\n      <td>0.494053</td>\n      <td>-2.098002</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.053639</td>\n      <td>-0.288431</td>\n      <td>0.096173</td>\n      <td>-0.151598</td>\n      <td>0.179133</td>\n      <td>0.025855</td>\n      <td>0.221040</td>\n      <td>0.155626</td>\n      <td>-0.151701</td>\n      <td>-0.016146</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3535</th>\n      <td>0.584270</td>\n      <td>-0.260586</td>\n      <td>0.011235</td>\n      <td>0.047950</td>\n      <td>-0.257241</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.090543</td>\n      <td>-0.110694</td>\n      <td>0.100748</td>\n      <td>0.411141</td>\n      <td>-0.191849</td>\n      <td>0.070196</td>\n      <td>-0.251843</td>\n      <td>0.062231</td>\n      <td>0.173676</td>\n      <td>-0.353208</td>\n    </tr>\n    <tr>\n      <th>3536</th>\n      <td>0.775281</td>\n      <td>-0.246429</td>\n      <td>-3.035245</td>\n      <td>-2.150702</td>\n      <td>1.691799</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.031045</td>\n      <td>0.055816</td>\n      <td>0.341487</td>\n      <td>-0.143810</td>\n      <td>0.275008</td>\n      <td>0.035487</td>\n      <td>-0.250839</td>\n      <td>-0.502362</td>\n      <td>-0.521410</td>\n      <td>0.010129</td>\n    </tr>\n    <tr>\n      <th>3537</th>\n      <td>0.730337</td>\n      <td>-0.271509</td>\n      <td>0.349733</td>\n      <td>-1.545276</td>\n      <td>-0.148961</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.156029</td>\n      <td>0.231721</td>\n      <td>-0.045153</td>\n      <td>0.440696</td>\n      <td>-0.110274</td>\n      <td>0.025682</td>\n      <td>-0.034410</td>\n      <td>-0.120474</td>\n      <td>0.086602</td>\n      <td>-0.152570</td>\n    </tr>\n    <tr>\n      <th>3538</th>\n      <td>0.719101</td>\n      <td>0.046586</td>\n      <td>0.772856</td>\n      <td>0.175408</td>\n      <td>0.500719</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.156725</td>\n      <td>-0.109072</td>\n      <td>0.018352</td>\n      <td>-0.131649</td>\n      <td>-0.065725</td>\n      <td>-0.041340</td>\n      <td>-0.030564</td>\n      <td>-0.380415</td>\n      <td>0.054779</td>\n      <td>-0.108390</td>\n    </tr>\n    <tr>\n      <th>3539</th>\n      <td>0.337079</td>\n      <td>-0.245196</td>\n      <td>0.265109</td>\n      <td>0.016085</td>\n      <td>-0.148961</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.108369</td>\n      <td>0.112168</td>\n      <td>-0.168308</td>\n      <td>0.181592</td>\n      <td>0.101270</td>\n      <td>-0.011321</td>\n      <td>-0.133576</td>\n      <td>0.074869</td>\n      <td>0.236674</td>\n      <td>0.020680</td>\n    </tr>\n  </tbody>\n</table>\n<p>3540 rows × 233 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DR_df = combineNonReducedEmb(non_emb_df, df_reduced_emb)\n",
    "DR_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5637240418867482"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression\n",
    "reg1 = LinearRegression()\n",
    "reg1.fit(DR_df, np.log(Y1))\n",
    "reg1.score(DR_df, np.log(Y1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "importance = reg1.coef_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 2.21398937e+00,  6.25713590e-01, -6.82060581e-02,  1.44249907e-01,\n       -8.58270225e-01,  9.36240466e-01,  6.36303507e-01,  3.49632320e-01,\n        7.77671442e-01,  4.23811381e-01,  1.28914033e-02, -5.68283974e-01,\n        6.60019934e-03,  6.53927407e-01,  5.96795454e-01, -1.84220372e+00,\n       -2.53099212e-01,  6.15664186e-01,  5.44597828e-01,  3.22140866e-01,\n        2.13017000e-01,  6.18761763e-02,  2.69366238e+00, -1.38532266e+00,\n       -2.59312077e-01,  3.85837240e-01, -5.67818014e-02,  2.15856384e+00,\n        7.53362170e-01,  1.83913009e-01, -4.90196138e-02, -1.24923420e-01,\n        7.84964563e+01, -4.18891496e+12, -2.12134283e-02, -3.42789450e-02,\n       -6.44459190e-02,  1.94744007e-02, -3.07408894e-02, -1.73848642e-02,\n        3.20253758e-01, -1.24740007e-01, -1.00381483e-01, -1.45444052e-01,\n       -7.35509805e-02, -3.00925317e-02, -1.04105226e-02, -1.91268560e-01,\n        1.34219652e-02, -3.05055687e-01,  1.20440153e-01,  1.21059560e-01,\n       -3.71240074e-02,  3.43221048e-01,  1.89896050e-02, -2.22315050e-01,\n        2.78033392e-01, -9.85556056e-02, -2.45204316e-01, -4.07787490e-02,\n       -3.25789439e-02, -9.68637857e-02, -2.28351010e-01,  1.52453611e-01,\n        5.47281925e-02, -1.19832906e-01, -1.49000193e-01,  4.40734604e-02,\n       -8.21115332e-02,  5.67873360e-02, -1.24837976e-01,  1.10379291e-01,\n       -1.72552289e-02,  1.42148335e-02,  2.78801599e-02, -1.37561285e-01,\n       -2.29608274e-01, -3.71639321e-02, -1.74227082e-01,  1.38903755e-01,\n       -1.80196127e-01,  6.66622849e-02,  7.35280806e-02,  1.12589672e-01,\n       -6.29925888e-02, -3.78152521e-02,  2.52071302e-01, -1.14189771e-01,\n        1.77733131e-01,  4.34817921e-02, -3.98985692e-02,  6.35074633e-02,\n        2.09498536e-01,  1.96867527e-01, -3.78713180e-02, -1.32367489e-01,\n        3.24617192e-01,  1.84333091e-02,  2.29586714e-01, -5.13490799e-02,\n        6.52819594e-02,  2.46781015e-01,  1.04173689e-02, -2.52469968e-02,\n        7.92072253e-02, -2.20619533e-01, -4.13247341e-01, -1.87078653e-01,\n        1.06961984e-01, -3.87215962e-02,  1.34437970e-01, -6.94768204e-02,\n       -2.78006903e-01,  2.85238713e-01,  4.90068089e-02, -2.52330652e-01,\n        6.93982371e-02, -4.90979384e-02,  3.97917315e-01, -1.59977486e-01,\n       -2.03565804e-01,  7.26257257e-02, -4.33653306e-02, -2.02159670e-01,\n        1.42424134e-01, -1.74127192e-01, -4.26159603e-02,  2.52000029e-01,\n        2.41896956e-01,  1.10848571e-01, -1.99632825e-01, -2.09364102e-02,\n       -1.07510081e-03, -5.97497511e-02, -4.90140064e-01,  1.68398851e-03,\n       -3.54153147e-02,  2.40138857e-01,  3.93747503e-01, -9.97886631e-03,\n        1.49750771e-01, -2.03902870e-01,  2.10052090e-01, -1.90659396e-01,\n        3.44426121e-01, -1.54265411e-01, -3.64019896e-01, -1.56872062e-01,\n        3.92590716e-01,  2.90424546e-01, -1.95456394e-02, -1.80381784e-01,\n       -1.98227837e-01,  2.02087535e-01,  3.63877127e-02, -2.31570696e-01,\n       -3.03293559e-01, -1.35873820e-01,  1.73499934e-01,  4.93937957e-02,\n       -4.81307666e-01,  1.48394477e-01,  1.69421209e-01, -1.02337853e-01,\n        1.71753011e-02, -4.01970385e-02,  3.61570591e-03,  3.51865500e-02,\n        4.52902667e-02,  2.19322650e-01,  2.80574105e-01, -2.68274331e-01,\n       -5.62693832e-02, -1.46888431e-01,  3.40699566e-01,  2.21078460e-01,\n        1.08809507e-01, -3.36805920e-02,  3.04393077e-01,  2.70179583e-01,\n       -2.85027953e-02, -2.43644528e-02,  1.84135080e-02, -2.70535905e-01,\n        1.52103494e-01,  1.05566292e-01,  5.72535105e-02,  1.93620399e-01,\n       -4.77701708e-02, -4.16132190e-01, -1.68439539e-01,  1.95777914e-02,\n       -7.52045256e-02, -2.82072152e-01,  6.04288988e-02,  3.61590527e-01,\n       -7.61515486e-01,  1.14663488e-01,  6.09738797e-02,  2.80903845e-02,\n       -7.69277245e-02,  5.59563678e-02,  3.56157816e-01,  6.04706866e-02,\n        7.41897646e-02,  8.83463398e-02, -1.39160328e-01,  3.88730257e-01,\n       -3.33190896e-01, -2.02845157e-01, -1.02076272e-01, -1.33294866e-01,\n       -2.44713162e-01, -5.37869647e-01, -1.46315497e-02,  1.47197166e-01,\n        5.92747774e-01, -3.48652751e-01, -1.70098530e-01,  1.74889791e-01,\n       -3.62086544e-01, -2.21389487e-01, -3.56110310e-01, -1.66289701e-01,\n       -2.61812252e-01,  6.35827932e-01,  2.32465196e-01, -3.69895832e-01,\n       -3.76471064e-02, -3.45073832e-01, -7.51461243e-02,  2.90363078e-01,\n       -2.70088360e-01])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 Feature Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# feature_selection = SelectPercentile(mutual_info_regression, percentile=5)\n",
    "# # feature_selection.fit(DR_df.to_numpy(), Y1.to_numpy().ravel())\n",
    "# pip2 = Pipeline([\n",
    "#\n",
    "# ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# embeded_rf_selector = SelectFromModel(RandomForestRegressor(n_estimators=100, random_state=42), max_features=50)\n",
    "# embeded_rf_selector.fit(DR_df, Y1.to_numpy().ravel())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:   42.8s finished\n",
      "\n",
      "[2022-12-13 13:52:29] Features: 1/33 -- score: 0.5041508970136526[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:   59.8s finished\n",
      "\n",
      "[2022-12-13 13:53:29] Features: 2/33 -- score: 0.5938532154027604[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  2.5min finished\n",
      "\n",
      "[2022-12-13 13:56:01] Features: 3/33 -- score: 0.6966879044905594[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  3.0min finished\n",
      "\n",
      "[2022-12-13 13:59:03] Features: 4/33 -- score: 0.7167149835285678[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  3.9min finished\n",
      "\n",
      "[2022-12-13 14:02:56] Features: 5/33 -- score: 0.7247619399185131[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  3.7min finished\n",
      "\n",
      "[2022-12-13 14:06:35] Features: 6/33 -- score: 0.7271782110803843[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  4.1min finished\n",
      "\n",
      "[2022-12-13 14:10:39] Features: 7/33 -- score: 0.7301872553138382[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  3.8min finished\n",
      "\n",
      "[2022-12-13 14:14:28] Features: 8/33 -- score: 0.7338699078209329[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  4.1min finished\n",
      "\n",
      "[2022-12-13 14:18:31] Features: 9/33 -- score: 0.7344375558194246[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  3.6min finished\n",
      "\n",
      "[2022-12-13 14:22:06] Features: 10/33 -- score: 0.7371680197423703[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  3.9min finished\n",
      "\n",
      "[2022-12-13 14:25:58] Features: 11/33 -- score: 0.738694487842047[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  3.9min finished\n",
      "\n",
      "[2022-12-13 14:29:50] Features: 12/33 -- score: 0.7387536809612641[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  4.1min finished\n",
      "\n",
      "[2022-12-13 14:33:56] Features: 13/33 -- score: 0.7386061658445865[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  3.9min finished\n",
      "\n",
      "[2022-12-13 14:37:48] Features: 14/33 -- score: 0.7390219694339966[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  3.6min finished\n",
      "\n",
      "[2022-12-13 14:41:26] Features: 15/33 -- score: 0.7406914417097719[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  3.7min finished\n",
      "\n",
      "[2022-12-13 14:45:06] Features: 16/33 -- score: 0.740088185492677[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  3.2min finished\n",
      "\n",
      "[2022-12-13 14:48:19] Features: 17/33 -- score: 0.7405490965008992[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  3.1min finished\n",
      "\n",
      "[2022-12-13 14:51:24] Features: 18/33 -- score: 0.7406420561907903[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  2.9min finished\n",
      "\n",
      "[2022-12-13 14:54:20] Features: 19/33 -- score: 0.7404034802946267[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  2.8min finished\n",
      "\n",
      "[2022-12-13 14:57:09] Features: 20/33 -- score: 0.742128369620033[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  2.6min finished\n",
      "\n",
      "[2022-12-13 14:59:45] Features: 21/33 -- score: 0.7399977266288225[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  2.5min finished\n",
      "\n",
      "[2022-12-13 15:02:13] Features: 22/33 -- score: 0.7409581999415241[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  2.3min finished\n",
      "\n",
      "[2022-12-13 15:04:31] Features: 23/33 -- score: 0.740368673275036[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:  2.1min finished\n",
      "\n",
      "[2022-12-13 15:06:38] Features: 24/33 -- score: 0.740472417998103[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.9min finished\n",
      "\n",
      "[2022-12-13 15:08:34] Features: 25/33 -- score: 0.7409226606675432[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.9min finished\n",
      "\n",
      "[2022-12-13 15:10:29] Features: 26/33 -- score: 0.7399231234548793[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.4min finished\n",
      "\n",
      "[2022-12-13 15:12:50] Features: 27/33 -- score: 0.7400683079585483[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   14.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  2.0min finished\n",
      "\n",
      "[2022-12-13 15:14:50] Features: 28/33 -- score: 0.7406525657194166[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.3min finished\n",
      "\n",
      "[2022-12-13 15:16:08] Features: 29/33 -- score: 0.7392864057378891[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.1min finished\n",
      "\n",
      "[2022-12-13 15:17:12] Features: 30/33 -- score: 0.7399057496421145[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   53.6s finished\n",
      "\n",
      "[2022-12-13 15:18:06] Features: 31/33 -- score: 0.7383072214350564[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   40.3s finished\n",
      "\n",
      "[2022-12-13 15:18:46] Features: 32/33 -- score: 0.7393996574199895[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   27.2s finished\n",
      "\n",
      "[2022-12-13 15:19:13] Features: 33/33 -- score: 0.7383132355450537"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "sfs = SFS(rfr, k_features=33, forward=True, verbose=2, scoring='r2', cv=10)\n",
    "sfs = sfs.fit(non_emb_df, np.log(1+Y1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "torch.save(sfs, \"sfs\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9647685258245127"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr1 = RandomForestRegressor().fit(non_emb_df, np.log(1+Y1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "(0,\n 1,\n 2,\n 3,\n 4,\n 5,\n 6,\n 7,\n 8,\n 9,\n 10,\n 11,\n 12,\n 13,\n 14,\n 15,\n 16,\n 17,\n 18,\n 19,\n 20,\n 21,\n 22,\n 23,\n 24,\n 25,\n 27,\n 28,\n 29,\n 30,\n 31,\n 32,\n 33)"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.k_feature_idx_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  1.4min finished\n",
      "\n",
      "[2022-12-13 18:48:43] Features: 1/20 -- score: 0.5041077558955636[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  1.4min finished\n",
      "\n",
      "[2022-12-13 18:50:04] Features: 2/20 -- score: 0.5978498685280604[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  2.1min finished\n",
      "\n",
      "[2022-12-13 18:52:10] Features: 3/20 -- score: 0.6975450819532389[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  1.9min finished\n",
      "\n",
      "[2022-12-13 18:54:07] Features: 4/20 -- score: 0.7162078909029431[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.9min finished\n",
      "\n",
      "[2022-12-13 18:56:02] Features: 5/20 -- score: 0.7232074212142676[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  2.0min finished\n",
      "\n",
      "[2022-12-13 18:58:01] Features: 6/20 -- score: 0.7312617683601867[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  1.9min finished\n",
      "\n",
      "[2022-12-13 18:59:54] Features: 7/20 -- score: 0.7307798225214986[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.9min finished\n",
      "\n",
      "[2022-12-13 19:01:46] Features: 8/20 -- score: 0.7323152099183162[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  1.8min finished\n",
      "\n",
      "[2022-12-13 19:03:33] Features: 9/20 -- score: 0.7338781074516569[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.8min finished\n",
      "\n",
      "[2022-12-13 19:05:19] Features: 10/20 -- score: 0.7346838227131645[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  1.7min finished\n",
      "\n",
      "[2022-12-13 19:07:01] Features: 11/20 -- score: 0.7350361689171633[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  1.6min finished\n",
      "\n",
      "[2022-12-13 19:08:39] Features: 12/20 -- score: 0.7374666567332812[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  1.6min finished\n",
      "\n",
      "[2022-12-13 19:10:16] Features: 13/20 -- score: 0.7390127853076589[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  1.5min finished\n",
      "\n",
      "[2022-12-13 19:11:48] Features: 14/20 -- score: 0.7374137291417064[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.5min finished\n",
      "\n",
      "[2022-12-13 19:13:18] Features: 15/20 -- score: 0.7386945662029761[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  1.4min finished\n",
      "\n",
      "[2022-12-13 19:14:43] Features: 16/20 -- score: 0.7391336604325758[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  1.3min finished\n",
      "\n",
      "[2022-12-13 19:16:03] Features: 17/20 -- score: 0.7404288164107546[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  1.3min finished\n",
      "\n",
      "[2022-12-13 19:17:19] Features: 18/20 -- score: 0.7388835767381565[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  1.2min finished\n",
      "\n",
      "[2022-12-13 19:18:32] Features: 19/20 -- score: 0.7399542899877766[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.2min finished\n",
      "\n",
      "[2022-12-13 19:19:44] Features: 20/20 -- score: 0.7411025999167815"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "rfr = RandomForestRegressor(n_jobs=-1)\n",
    "sfs_20features = SequentialFeatureSelector(\n",
    "    rfr,\n",
    "    k_features=20,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    verbose=2,\n",
    "    scoring='r2',\n",
    "    cv=10,\n",
    ").fit(non_emb_df, np.log(1 + Y1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "torch.save(sfs_20features, \"../models/foward_feature_selection_20features\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "sfs_20 = torch.load(\"../models/foward_feature_selection_20features\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                                          feature_idx  \\\n1                                               (32,)   \n2                                             (1, 32)   \n3                                          (1, 4, 32)   \n4                                       (1, 3, 4, 32)   \n5                                    (0, 1, 3, 4, 32)   \n6                                 (0, 1, 3, 4, 5, 32)   \n7                             (0, 1, 3, 4, 5, 29, 32)   \n8                         (0, 1, 3, 4, 5, 27, 29, 32)   \n9                     (0, 1, 3, 4, 5, 12, 27, 29, 32)   \n10                (0, 1, 3, 4, 5, 12, 27, 29, 31, 32)   \n11            (0, 1, 3, 4, 5, 10, 12, 27, 29, 31, 32)   \n12        (0, 1, 3, 4, 5, 10, 12, 13, 27, 29, 31, 32)   \n13    (0, 1, 3, 4, 5, 10, 12, 13, 14, 27, 29, 31, 32)   \n14  (0, 1, 3, 4, 5, 7, 10, 12, 13, 14, 27, 29, 31,...   \n15  (0, 1, 3, 4, 5, 7, 10, 12, 13, 14, 18, 27, 29,...   \n16  (0, 1, 3, 4, 5, 7, 10, 12, 13, 14, 18, 25, 27,...   \n17  (0, 1, 3, 4, 5, 7, 10, 12, 13, 14, 17, 18, 25,...   \n18  (0, 1, 3, 4, 5, 7, 10, 12, 13, 14, 17, 18, 21,...   \n19  (0, 1, 2, 3, 4, 5, 7, 10, 12, 13, 14, 17, 18, ...   \n20  (0, 1, 2, 3, 4, 5, 7, 10, 12, 13, 14, 17, 18, ...   \n\n                                            cv_scores avg_score  \\\n1   [0.517815313938865, 0.5474465442293487, 0.5177...  0.504108   \n2   [0.6491622718105017, 0.6171114357033527, 0.632...   0.59785   \n3   [0.7360864128002844, 0.7198908514784774, 0.746...  0.697545   \n4   [0.7657098206541477, 0.7410537328090163, 0.751...  0.716208   \n5   [0.7668178531303946, 0.7357804756292788, 0.753...  0.723207   \n6   [0.7776944910287957, 0.7386240426950382, 0.759...  0.731262   \n7   [0.7741432623448815, 0.7325063943479908, 0.763...   0.73078   \n8   [0.7723286138655876, 0.7364592379474155, 0.764...  0.732315   \n9   [0.7823437956204866, 0.7394022850186523, 0.767...  0.733878   \n10  [0.7761595572402359, 0.7427339332727853, 0.764...  0.734684   \n11  [0.7799630673290148, 0.7400321779009182, 0.765...  0.735036   \n12  [0.7750817363602297, 0.7429605214335764, 0.770...  0.737467   \n13  [0.7811658466426213, 0.7401376601352303, 0.768...  0.739013   \n14  [0.7775300394403879, 0.7437036380919089, 0.765...  0.737414   \n15  [0.7739582942184297, 0.7458619940483242, 0.777...  0.738695   \n16  [0.7762754714988689, 0.7418637888621973, 0.770...  0.739134   \n17  [0.7784688530551607, 0.7454225916726227, 0.778...  0.740429   \n18  [0.7727596777135302, 0.7462867754441551, 0.782...  0.738884   \n19  [0.7723258759701925, 0.748776461543195, 0.7764...  0.739954   \n20  [0.7737159661754681, 0.7517296551992954, 0.778...  0.741103   \n\n                                        feature_names  ci_bound   std_dev  \\\n1                                      (studio_freq,)  0.028846  0.038839   \n2                              (n_votes, studio_freq)   0.03361  0.045252   \n3                (n_votes, release_year, studio_freq)  0.039453   0.05312   \n4       (n_votes, runtime, release_year, studio_freq)  0.035622  0.047962   \n5   (ratings, n_votes, runtime, release_year, stud...  0.035294   0.04752   \n6   (ratings, n_votes, runtime, release_year, Acti...  0.031573  0.042511   \n7   (ratings, n_votes, runtime, release_year, Acti...  0.030826  0.041504   \n8   (ratings, n_votes, runtime, release_year, Acti...   0.03111  0.041887   \n9   (ratings, n_votes, runtime, release_year, Acti...   0.03005  0.040459   \n10  (ratings, n_votes, runtime, release_year, Acti...   0.02903  0.039087   \n11  (ratings, n_votes, runtime, release_year, Acti...  0.030841  0.041525   \n12  (ratings, n_votes, runtime, release_year, Acti...  0.029298  0.039447   \n13  (ratings, n_votes, runtime, release_year, Acti...  0.029908  0.040269   \n14  (ratings, n_votes, runtime, release_year, Acti...  0.027551  0.037095   \n15  (ratings, n_votes, runtime, release_year, Acti...  0.027008  0.036364   \n16  (ratings, n_votes, runtime, release_year, Acti...  0.027205   0.03663   \n17  (ratings, n_votes, runtime, release_year, Acti...  0.028005  0.037706   \n18  (ratings, n_votes, runtime, release_year, Acti...  0.029026  0.039081   \n19  (ratings, n_votes, production_year, runtime, r...  0.024198   0.03258   \n20  (ratings, n_votes, production_year, runtime, r...  0.025173  0.033893   \n\n     std_err  \n1   0.012946  \n2   0.015084  \n3   0.017707  \n4   0.015987  \n5    0.01584  \n6    0.01417  \n7   0.013835  \n8   0.013962  \n9   0.013486  \n10  0.013029  \n11  0.013842  \n12  0.013149  \n13  0.013423  \n14  0.012365  \n15  0.012121  \n16   0.01221  \n17  0.012569  \n18  0.013027  \n19   0.01086  \n20  0.011298  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_idx</th>\n      <th>cv_scores</th>\n      <th>avg_score</th>\n      <th>feature_names</th>\n      <th>ci_bound</th>\n      <th>std_dev</th>\n      <th>std_err</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>(32,)</td>\n      <td>[0.517815313938865, 0.5474465442293487, 0.5177...</td>\n      <td>0.504108</td>\n      <td>(studio_freq,)</td>\n      <td>0.028846</td>\n      <td>0.038839</td>\n      <td>0.012946</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(1, 32)</td>\n      <td>[0.6491622718105017, 0.6171114357033527, 0.632...</td>\n      <td>0.59785</td>\n      <td>(n_votes, studio_freq)</td>\n      <td>0.03361</td>\n      <td>0.045252</td>\n      <td>0.015084</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(1, 4, 32)</td>\n      <td>[0.7360864128002844, 0.7198908514784774, 0.746...</td>\n      <td>0.697545</td>\n      <td>(n_votes, release_year, studio_freq)</td>\n      <td>0.039453</td>\n      <td>0.05312</td>\n      <td>0.017707</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(1, 3, 4, 32)</td>\n      <td>[0.7657098206541477, 0.7410537328090163, 0.751...</td>\n      <td>0.716208</td>\n      <td>(n_votes, runtime, release_year, studio_freq)</td>\n      <td>0.035622</td>\n      <td>0.047962</td>\n      <td>0.015987</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>(0, 1, 3, 4, 32)</td>\n      <td>[0.7668178531303946, 0.7357804756292788, 0.753...</td>\n      <td>0.723207</td>\n      <td>(ratings, n_votes, runtime, release_year, stud...</td>\n      <td>0.035294</td>\n      <td>0.04752</td>\n      <td>0.01584</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>(0, 1, 3, 4, 5, 32)</td>\n      <td>[0.7776944910287957, 0.7386240426950382, 0.759...</td>\n      <td>0.731262</td>\n      <td>(ratings, n_votes, runtime, release_year, Acti...</td>\n      <td>0.031573</td>\n      <td>0.042511</td>\n      <td>0.01417</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>(0, 1, 3, 4, 5, 29, 32)</td>\n      <td>[0.7741432623448815, 0.7325063943479908, 0.763...</td>\n      <td>0.73078</td>\n      <td>(ratings, n_votes, runtime, release_year, Acti...</td>\n      <td>0.030826</td>\n      <td>0.041504</td>\n      <td>0.013835</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>(0, 1, 3, 4, 5, 27, 29, 32)</td>\n      <td>[0.7723286138655876, 0.7364592379474155, 0.764...</td>\n      <td>0.732315</td>\n      <td>(ratings, n_votes, runtime, release_year, Acti...</td>\n      <td>0.03111</td>\n      <td>0.041887</td>\n      <td>0.013962</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>(0, 1, 3, 4, 5, 12, 27, 29, 32)</td>\n      <td>[0.7823437956204866, 0.7394022850186523, 0.767...</td>\n      <td>0.733878</td>\n      <td>(ratings, n_votes, runtime, release_year, Acti...</td>\n      <td>0.03005</td>\n      <td>0.040459</td>\n      <td>0.013486</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>(0, 1, 3, 4, 5, 12, 27, 29, 31, 32)</td>\n      <td>[0.7761595572402359, 0.7427339332727853, 0.764...</td>\n      <td>0.734684</td>\n      <td>(ratings, n_votes, runtime, release_year, Acti...</td>\n      <td>0.02903</td>\n      <td>0.039087</td>\n      <td>0.013029</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>(0, 1, 3, 4, 5, 10, 12, 27, 29, 31, 32)</td>\n      <td>[0.7799630673290148, 0.7400321779009182, 0.765...</td>\n      <td>0.735036</td>\n      <td>(ratings, n_votes, runtime, release_year, Acti...</td>\n      <td>0.030841</td>\n      <td>0.041525</td>\n      <td>0.013842</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>(0, 1, 3, 4, 5, 10, 12, 13, 27, 29, 31, 32)</td>\n      <td>[0.7750817363602297, 0.7429605214335764, 0.770...</td>\n      <td>0.737467</td>\n      <td>(ratings, n_votes, runtime, release_year, Acti...</td>\n      <td>0.029298</td>\n      <td>0.039447</td>\n      <td>0.013149</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>(0, 1, 3, 4, 5, 10, 12, 13, 14, 27, 29, 31, 32)</td>\n      <td>[0.7811658466426213, 0.7401376601352303, 0.768...</td>\n      <td>0.739013</td>\n      <td>(ratings, n_votes, runtime, release_year, Acti...</td>\n      <td>0.029908</td>\n      <td>0.040269</td>\n      <td>0.013423</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>(0, 1, 3, 4, 5, 7, 10, 12, 13, 14, 27, 29, 31,...</td>\n      <td>[0.7775300394403879, 0.7437036380919089, 0.765...</td>\n      <td>0.737414</td>\n      <td>(ratings, n_votes, runtime, release_year, Acti...</td>\n      <td>0.027551</td>\n      <td>0.037095</td>\n      <td>0.012365</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>(0, 1, 3, 4, 5, 7, 10, 12, 13, 14, 18, 27, 29,...</td>\n      <td>[0.7739582942184297, 0.7458619940483242, 0.777...</td>\n      <td>0.738695</td>\n      <td>(ratings, n_votes, runtime, release_year, Acti...</td>\n      <td>0.027008</td>\n      <td>0.036364</td>\n      <td>0.012121</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>(0, 1, 3, 4, 5, 7, 10, 12, 13, 14, 18, 25, 27,...</td>\n      <td>[0.7762754714988689, 0.7418637888621973, 0.770...</td>\n      <td>0.739134</td>\n      <td>(ratings, n_votes, runtime, release_year, Acti...</td>\n      <td>0.027205</td>\n      <td>0.03663</td>\n      <td>0.01221</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>(0, 1, 3, 4, 5, 7, 10, 12, 13, 14, 17, 18, 25,...</td>\n      <td>[0.7784688530551607, 0.7454225916726227, 0.778...</td>\n      <td>0.740429</td>\n      <td>(ratings, n_votes, runtime, release_year, Acti...</td>\n      <td>0.028005</td>\n      <td>0.037706</td>\n      <td>0.012569</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>(0, 1, 3, 4, 5, 7, 10, 12, 13, 14, 17, 18, 21,...</td>\n      <td>[0.7727596777135302, 0.7462867754441551, 0.782...</td>\n      <td>0.738884</td>\n      <td>(ratings, n_votes, runtime, release_year, Acti...</td>\n      <td>0.029026</td>\n      <td>0.039081</td>\n      <td>0.013027</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>(0, 1, 2, 3, 4, 5, 7, 10, 12, 13, 14, 17, 18, ...</td>\n      <td>[0.7723258759701925, 0.748776461543195, 0.7764...</td>\n      <td>0.739954</td>\n      <td>(ratings, n_votes, production_year, runtime, r...</td>\n      <td>0.024198</td>\n      <td>0.03258</td>\n      <td>0.01086</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>(0, 1, 2, 3, 4, 5, 7, 10, 12, 13, 14, 17, 18, ...</td>\n      <td>[0.7737159661754681, 0.7517296551992954, 0.778...</td>\n      <td>0.741103</td>\n      <td>(ratings, n_votes, production_year, runtime, r...</td>\n      <td>0.025173</td>\n      <td>0.033893</td>\n      <td>0.011298</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(sfs_20.get_metric_dict()).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  1.4min finished\n",
      "\n",
      "[2022-12-13 19:30:47] Features: 1/34 -- score: 0.5041077558955636[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  1.4min finished\n",
      "\n",
      "[2022-12-13 19:32:08] Features: 2/34 -- score: 0.5978498685280604[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  2.1min finished\n",
      "\n",
      "[2022-12-13 19:34:16] Features: 3/34 -- score: 0.6975450819532389[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  1.9min finished\n",
      "\n",
      "[2022-12-13 19:36:12] Features: 4/34 -- score: 0.7162078909029431[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.0min finished\n",
      "\n",
      "[2022-12-13 19:38:14] Features: 5/34 -- score: 0.7232074212142675[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  2.1min finished\n",
      "\n",
      "[2022-12-13 19:40:19] Features: 6/34 -- score: 0.7312617683601867[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  1.9min finished\n",
      "\n",
      "[2022-12-13 19:42:14] Features: 7/34 -- score: 0.7307798225214986[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.9min finished\n",
      "\n",
      "[2022-12-13 19:44:09] Features: 8/34 -- score: 0.7323152099183162[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  1.8min finished\n",
      "\n",
      "[2022-12-13 19:45:58] Features: 9/34 -- score: 0.7338781074516569[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.9min finished\n",
      "\n",
      "[2022-12-13 19:47:52] Features: 10/34 -- score: 0.7346838227131645[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  1.7min finished\n",
      "\n",
      "[2022-12-13 19:49:31] Features: 11/34 -- score: 0.7350361689171632[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  1.6min finished\n",
      "\n",
      "[2022-12-13 19:51:05] Features: 12/34 -- score: 0.7374666567332812[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  1.8min finished\n",
      "\n",
      "[2022-12-13 19:52:55] Features: 13/34 -- score: 0.7390127853076589[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  1.9min finished\n",
      "\n",
      "[2022-12-13 19:54:51] Features: 14/34 -- score: 0.7374137291417064[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.6min finished\n",
      "\n",
      "[2022-12-13 19:56:26] Features: 15/34 -- score: 0.7386945662029761[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  1.4min finished\n",
      "\n",
      "[2022-12-13 19:57:52] Features: 16/34 -- score: 0.7391336604325758[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  1.5min finished\n",
      "\n",
      "[2022-12-13 19:59:21] Features: 17/34 -- score: 0.7404288164107548[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  1.4min finished\n",
      "\n",
      "[2022-12-13 20:00:44] Features: 18/34 -- score: 0.7388835767381565[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  1.3min finished\n",
      "\n",
      "[2022-12-13 20:02:04] Features: 19/34 -- score: 0.7399542899877766[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.3min finished\n",
      "\n",
      "[2022-12-13 20:03:21] Features: 20/34 -- score: 0.7411025999167815[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  1.2min finished\n",
      "\n",
      "[2022-12-13 20:04:32] Features: 21/34 -- score: 0.7395680020153701[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  1.0min finished\n",
      "\n",
      "[2022-12-13 20:05:35] Features: 22/34 -- score: 0.739123001479291[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  1.2min finished\n",
      "\n",
      "[2022-12-13 20:06:49] Features: 23/34 -- score: 0.7397594344112379[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   55.4s finished\n",
      "\n",
      "[2022-12-13 20:07:44] Features: 24/34 -- score: 0.7394536103057802[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   53.2s finished\n",
      "\n",
      "[2022-12-13 20:08:37] Features: 25/34 -- score: 0.740069432934673[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   49.1s finished\n",
      "\n",
      "[2022-12-13 20:09:26] Features: 26/34 -- score: 0.7396217983645923[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   41.7s finished\n",
      "\n",
      "[2022-12-13 20:10:08] Features: 27/34 -- score: 0.7397665815862495[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   36.3s finished\n",
      "\n",
      "[2022-12-13 20:10:44] Features: 28/34 -- score: 0.7399484853097162[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   32.6s finished\n",
      "\n",
      "[2022-12-13 20:11:17] Features: 29/34 -- score: 0.7384828765910119[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   27.0s finished\n",
      "\n",
      "[2022-12-13 20:11:44] Features: 30/34 -- score: 0.7390277590655943[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   22.4s finished\n",
      "\n",
      "[2022-12-13 20:12:06] Features: 31/34 -- score: 0.7371467162764173[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   17.5s finished\n",
      "\n",
      "[2022-12-13 20:12:24] Features: 32/34 -- score: 0.7400356126499232[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   10.8s finished\n",
      "\n",
      "[2022-12-13 20:12:35] Features: 33/34 -- score: 0.7378610974330548[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.6s finished\n",
      "\n",
      "[2022-12-13 20:12:40] Features: 34/34 -- score: 0.7390865330558858"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "rfr = RandomForestRegressor(n_jobs=-1)\n",
    "sfs_34features = SequentialFeatureSelector(\n",
    "    rfr,\n",
    "    k_features=34,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    verbose=2,\n",
    "    scoring='r2',\n",
    "    cv=10,\n",
    ").fit(non_emb_df, np.log(1 + Y1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "torch.save(sfs_34features, \"../models/foward_feature_selection_34features\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "sfs_34 = torch.load(\"../models/foward_feature_selection_20features\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_jobs=-1)\n",
    "efs = ExhaustiveFeatureSelector(\n",
    "    rfr,\n",
    "    min_features=1,\n",
    "    max_features=34,\n",
    "    scoring='r2',\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "efs.fit(non_emb_df, np.log(1 + Y1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def FeatureSelection(X, n_components=0.95):\n",
    "    renamed_df_ready = renamingDataset(X)\n",
    "    non_emb_df, img_emb_df, text_emb_df = divideDataset(renamed_df_ready)\n",
    "    reduced_emb_df = DRembeddings(img_emb_df, text_emb_df, n_components=n_components)\n",
    "    DR_df = combineNonReducedEmb(non_emb_df, reduced_emb_df)\n",
    "\n",
    "    return DR_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "feature_selection_transformer = FunctionTransformer(FeatureSelection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "p2 = Pipeline([\n",
    "    ('FeatureSelection', feature_selection_transformer),\n",
    "    # ('model', Lasso())\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "       ratings   n_votes  production_year   runtime  release_year  Action  \\\n0     0.606742  0.809200         1.111354  0.398460      0.933839     0.0   \n1     0.764045 -0.271776        -0.073389  0.079814      1.366959     1.0   \n2     0.539326 -0.256258        -1.596629  1.099479     -2.531122     0.0   \n3     0.617978 -0.215474        -0.242638  0.398460     -0.798642     0.0   \n4     0.337079 -0.265518        -1.258132  0.494053     -2.098002     0.0   \n...        ...       ...              ...       ...           ...     ...   \n3535  0.584270 -0.260586         0.011235  0.047950     -0.257241     0.0   \n3536  0.775281 -0.246429        -3.035245 -2.150702      1.691799     0.0   \n3537  0.730337 -0.271509         0.349733 -1.545276     -0.148961     0.0   \n3538  0.719101  0.046586         0.772856  0.175408      0.500719     0.0   \n3539  0.337079 -0.245196         0.265109  0.016085     -0.148961     0.0   \n\n      Adventure  Animation  Biography  Comedy  ...   emb_189   emb_190  \\\n0           1.0        0.0        0.0     1.0  ... -0.020153 -0.015117   \n1           0.0        0.0        0.0     0.0  ... -0.194736  0.081447   \n2           0.0        0.0        0.0     0.0  ...  0.092746  0.026760   \n3           0.0        0.0        1.0     0.0  ...  0.222160 -0.061716   \n4           0.0        0.0        0.0     0.0  ... -0.053639 -0.288431   \n...         ...        ...        ...     ...  ...       ...       ...   \n3535        0.0        0.0        0.0     1.0  ...  0.090543 -0.110694   \n3536        0.0        0.0        0.0     0.0  ... -0.031045  0.055816   \n3537        0.0        0.0        0.0     0.0  ... -0.156029  0.231721   \n3538        0.0        0.0        0.0     0.0  ...  0.156725 -0.109072   \n3539        0.0        0.0        0.0     1.0  ...  0.108369  0.112168   \n\n       emb_191   emb_192   emb_193   emb_194   emb_195   emb_196   emb_197  \\\n0     0.237029 -0.028050 -0.023873  0.079219 -0.031364 -0.071154 -0.091889   \n1     0.099483 -0.115929  0.107830  0.129517 -0.144803 -0.000834 -0.156755   \n2     0.241836  0.224205  0.007772  0.136998  0.067925 -0.050262  0.116298   \n3     0.269019 -0.029332  0.159303  0.049171  0.240762 -0.297771 -0.147129   \n4     0.096173 -0.151598  0.179133  0.025855  0.221040  0.155626 -0.151701   \n...        ...       ...       ...       ...       ...       ...       ...   \n3535  0.100748  0.411141 -0.191849  0.070196 -0.251843  0.062231  0.173676   \n3536  0.341487 -0.143810  0.275008  0.035487 -0.250839 -0.502362 -0.521410   \n3537 -0.045153  0.440696 -0.110274  0.025682 -0.034410 -0.120474  0.086602   \n3538  0.018352 -0.131649 -0.065725 -0.041340 -0.030564 -0.380415  0.054779   \n3539 -0.168308  0.181592  0.101270 -0.011321 -0.133576  0.074869  0.236674   \n\n       emb_198  \n0    -0.235259  \n1     0.159004  \n2     0.057964  \n3     0.116596  \n4    -0.016146  \n...        ...  \n3535 -0.353208  \n3536  0.010129  \n3537 -0.152570  \n3538 -0.108390  \n3539  0.020680  \n\n[3540 rows x 233 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ratings</th>\n      <th>n_votes</th>\n      <th>production_year</th>\n      <th>runtime</th>\n      <th>release_year</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Biography</th>\n      <th>Comedy</th>\n      <th>...</th>\n      <th>emb_189</th>\n      <th>emb_190</th>\n      <th>emb_191</th>\n      <th>emb_192</th>\n      <th>emb_193</th>\n      <th>emb_194</th>\n      <th>emb_195</th>\n      <th>emb_196</th>\n      <th>emb_197</th>\n      <th>emb_198</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.606742</td>\n      <td>0.809200</td>\n      <td>1.111354</td>\n      <td>0.398460</td>\n      <td>0.933839</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>-0.020153</td>\n      <td>-0.015117</td>\n      <td>0.237029</td>\n      <td>-0.028050</td>\n      <td>-0.023873</td>\n      <td>0.079219</td>\n      <td>-0.031364</td>\n      <td>-0.071154</td>\n      <td>-0.091889</td>\n      <td>-0.235259</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.764045</td>\n      <td>-0.271776</td>\n      <td>-0.073389</td>\n      <td>0.079814</td>\n      <td>1.366959</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.194736</td>\n      <td>0.081447</td>\n      <td>0.099483</td>\n      <td>-0.115929</td>\n      <td>0.107830</td>\n      <td>0.129517</td>\n      <td>-0.144803</td>\n      <td>-0.000834</td>\n      <td>-0.156755</td>\n      <td>0.159004</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.539326</td>\n      <td>-0.256258</td>\n      <td>-1.596629</td>\n      <td>1.099479</td>\n      <td>-2.531122</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.092746</td>\n      <td>0.026760</td>\n      <td>0.241836</td>\n      <td>0.224205</td>\n      <td>0.007772</td>\n      <td>0.136998</td>\n      <td>0.067925</td>\n      <td>-0.050262</td>\n      <td>0.116298</td>\n      <td>0.057964</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.617978</td>\n      <td>-0.215474</td>\n      <td>-0.242638</td>\n      <td>0.398460</td>\n      <td>-0.798642</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.222160</td>\n      <td>-0.061716</td>\n      <td>0.269019</td>\n      <td>-0.029332</td>\n      <td>0.159303</td>\n      <td>0.049171</td>\n      <td>0.240762</td>\n      <td>-0.297771</td>\n      <td>-0.147129</td>\n      <td>0.116596</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.337079</td>\n      <td>-0.265518</td>\n      <td>-1.258132</td>\n      <td>0.494053</td>\n      <td>-2.098002</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.053639</td>\n      <td>-0.288431</td>\n      <td>0.096173</td>\n      <td>-0.151598</td>\n      <td>0.179133</td>\n      <td>0.025855</td>\n      <td>0.221040</td>\n      <td>0.155626</td>\n      <td>-0.151701</td>\n      <td>-0.016146</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3535</th>\n      <td>0.584270</td>\n      <td>-0.260586</td>\n      <td>0.011235</td>\n      <td>0.047950</td>\n      <td>-0.257241</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.090543</td>\n      <td>-0.110694</td>\n      <td>0.100748</td>\n      <td>0.411141</td>\n      <td>-0.191849</td>\n      <td>0.070196</td>\n      <td>-0.251843</td>\n      <td>0.062231</td>\n      <td>0.173676</td>\n      <td>-0.353208</td>\n    </tr>\n    <tr>\n      <th>3536</th>\n      <td>0.775281</td>\n      <td>-0.246429</td>\n      <td>-3.035245</td>\n      <td>-2.150702</td>\n      <td>1.691799</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.031045</td>\n      <td>0.055816</td>\n      <td>0.341487</td>\n      <td>-0.143810</td>\n      <td>0.275008</td>\n      <td>0.035487</td>\n      <td>-0.250839</td>\n      <td>-0.502362</td>\n      <td>-0.521410</td>\n      <td>0.010129</td>\n    </tr>\n    <tr>\n      <th>3537</th>\n      <td>0.730337</td>\n      <td>-0.271509</td>\n      <td>0.349733</td>\n      <td>-1.545276</td>\n      <td>-0.148961</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.156029</td>\n      <td>0.231721</td>\n      <td>-0.045153</td>\n      <td>0.440696</td>\n      <td>-0.110274</td>\n      <td>0.025682</td>\n      <td>-0.034410</td>\n      <td>-0.120474</td>\n      <td>0.086602</td>\n      <td>-0.152570</td>\n    </tr>\n    <tr>\n      <th>3538</th>\n      <td>0.719101</td>\n      <td>0.046586</td>\n      <td>0.772856</td>\n      <td>0.175408</td>\n      <td>0.500719</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.156725</td>\n      <td>-0.109072</td>\n      <td>0.018352</td>\n      <td>-0.131649</td>\n      <td>-0.065725</td>\n      <td>-0.041340</td>\n      <td>-0.030564</td>\n      <td>-0.380415</td>\n      <td>0.054779</td>\n      <td>-0.108390</td>\n    </tr>\n    <tr>\n      <th>3539</th>\n      <td>0.337079</td>\n      <td>-0.245196</td>\n      <td>0.265109</td>\n      <td>0.016085</td>\n      <td>-0.148961</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.108369</td>\n      <td>0.112168</td>\n      <td>-0.168308</td>\n      <td>0.181592</td>\n      <td>0.101270</td>\n      <td>-0.011321</td>\n      <td>-0.133576</td>\n      <td>0.074869</td>\n      <td>0.236674</td>\n      <td>0.020680</td>\n    </tr>\n  </tbody>\n</table>\n<p>3540 rows × 233 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.fit_transform(X1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1 Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   5.7s\n",
      "[CV] END .................................................... total time=   6.6s\n",
      "[CV] END .................................................... total time=   5.3s\n",
      "[CV] END .................................................... total time=   5.5s\n",
      "[CV] END .................................................... total time=   5.4s\n",
      "[CV] END .................................................... total time=   5.4s\n",
      "[CV] END .................................................... total time=   5.7s\n",
      "[CV] END .................................................... total time=   8.6s\n",
      "[CV] END .................................................... total time=   9.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([-190.62080506, -156.38776382, -297.10558592, -300.41254007,\n       -523.16780132, -453.39744215, -217.57674454,  -55.45779738,\n       -294.12843735, -153.87180725])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model = LinearRegression()\n",
    "scores = cross_val_score(LR_model, X1, Y1, cv=10, verbose=2)\n",
    "\n",
    "\n",
    "# kf = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "# train_scores = []\n",
    "# valid_scores = []\n",
    "#\n",
    "# for i, (train_index, valid_index) in enumerate(kf.split(X1)):\n",
    "#     X_train = X1[train_index,:]\n",
    "#     y_train = Y1[train_index]\n",
    "#     X_valid = X1[valid_index,:]\n",
    "#     y_valid = Y1[valid_index]\n",
    "#\n",
    "#     model.fit(X_train, np.log(1 + y_train))\n",
    "#     train_score = model.score(X_train, np.log(1 + y_train))\n",
    "#     valid_score = model.score(X_valid, np.log(1 + y_valid))\n",
    "#     train_scores.append(round(train_score, 6))\n",
    "#     valid_scores.append(round(valid_score, 6))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2 MLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "MLP_model = MLPRegressor(hidden_layer_sizes=(1000, 500, 100, 50),\n",
    "                         max_iter = 500, activation = 'relu',\n",
    "                         learning_rate='constant', learning_rate_init=0.001, random_state=42)\n",
    "\n",
    "# scores = cross_val_score(MLP_model, X1, Y1, cv=5, verbose=2)\n",
    "# # MLP_model.fit(X1, Y1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "MLPRegressor(hidden_layer_sizes=(1000, 500, 100, 50), max_iter=500,\n             random_state=42)"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_model.fit(X_train, np.log(1 + y_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4173746542215616"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_model.score(X_val, np.log(1 + y_val))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "y_pre = MLP_model.predict(X_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.41136217e+07, 1.63255000e+07],\n       [3.98230516e+08, 5.65297205e+07],\n       [1.04222857e+04, 2.33458623e+03],\n       ...,\n       [1.40858624e+06, 3.33221359e+05],\n       [3.46415615e+07, 2.03076076e+07],\n       [1.25996951e+04, 2.15869407e+04]])"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([y_val, np.exp(y_pre)]).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3 KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "0.10686212585720234"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_model = KNeighborsRegressor(n_neighbors = 150)\n",
    "KNN_model.fit(X_train, np.log(1 + y_train))\n",
    "KNN_model.score(X_val, np.log(1 + y_val))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.41136217e+07, 1.63255000e+07],\n       [3.98230516e+08, 5.65297205e+07],\n       [1.04222857e+04, 2.33458623e+03],\n       ...,\n       [1.40858624e+06, 3.33221359e+05],\n       [3.46415615e+07, 2.03076076e+07],\n       [1.25996951e+04, 2.15869407e+04]])"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre = MLP_model.predict(X_val)\n",
    "np.vstack([y_val, np.exp(y_pre)]).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

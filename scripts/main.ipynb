{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load the packages"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data processing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Machine learning packages\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_val_score, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MultiLabelBinarizer, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, RFE, SelectPercentile, chi2, mutual_info_regression, SelectFromModel\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "\n",
    "# Visualization packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Others\n",
    "import time\n",
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Read the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X1 = pd.read_csv(\"X1.csv\")\n",
    "Y1 = pd.read_csv(\"Y1.csv\", header=None, names=['revenue '])\n",
    "X2 = pd.read_csv(\"X2.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 1: Data Cleaning (columns drop off and missing value processing)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_cleaning_process(df):\n",
    "    \"\"\"\n",
    "    This function will drop columns, like \"Unnamed: 0\", \"title\", \"img_url\", \"description\" from the dataset, and replace the missing value in `runtime` column with a median value, and replace the missing value in `genres` with \"Others\".\n",
    "    :param df: A dataframe (X1 or X2)\n",
    "    :return: A new cleaned dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    new_df = df.copy()\n",
    "    # missing value for runtime: replace \"\\\\N\" with median value\n",
    "    median_runtime = np.median(new_df.loc[new_df['runtime'] != '\\\\N', 'runtime'].astype(np.int64))\n",
    "    new_df['runtime'] = np.where(new_df['runtime'] == '\\\\N', median_runtime, new_df['runtime']).astype(np.int64)\n",
    "\n",
    "    # missing value for genres: replace \"\\\\N\" with \"Others\"\n",
    "    new_df.loc[new_df['genres'] == \"\\\\N\", \"genres\"] = \"Others\"\n",
    "\n",
    "    # drop \"Unnamed: 0\", \"title\", \"img_url\", \"description\"\n",
    "    new_df = new_df.drop([\"Unnamed: 0\", \"title\", \"img_url\", \"description\"], axis=1)\n",
    "\n",
    "    return new_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X1_cleaned = data_cleaning_process(X1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2: Data Type Split (Numerical, Categorical, Embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_type_split(df):\n",
    "    \"\"\"\n",
    "    This function will split the whole dataset into different sub dataset according to the data types of the columns\n",
    "    :param df: A dataframe\n",
    "    :return: three datadrames, which are numerical, categorical, embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    new_df = df.copy()\n",
    "    numeric_features = new_df.select_dtypes(include=\"number\").columns.tolist()\n",
    "    non_numeric_features = new_df.select_dtypes(exclude=\"number\").columns.tolist()\n",
    "    embedding_features = ['img_embeddings', 'text_embeddings']\n",
    "    numeric_features.remove('is_adult')\n",
    "    categorical_features = non_numeric_features.copy()\n",
    "    [categorical_features.remove(col) for col in embedding_features]\n",
    "    categorical_features.append('is_adult')\n",
    "    return new_df.loc[:, numeric_features], new_df.loc[:, categorical_features], new_df.loc[:, embedding_features]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_num, df_cat, df_emb = data_type_split(X1_cleaned)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_num.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cat.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_emb.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 3: Categorical Columns Processing (Genres --> multilable binary type, Studio --> studio_frequency)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dict_cat_freq = torch.load(\"studio_freq\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "df_cat['genres_split'] = df_cat['genres'].apply(lambda x: x.split(\",\"))\n",
    "mlb.fit(df_cat['genres_split'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def categorical_process(df):\n",
    "    \"\"\"\n",
    "    This function will process on `genres` and `studio` columns.\n",
    "    `genres` will be transformed to multilabel binary variables;\n",
    "    `studio` will be transformed to a frequency type.\n",
    "    :param df: A categorical datframe\n",
    "    :return: A new dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    new_df = df.copy()\n",
    "\n",
    "    # processing on `genres` column\n",
    "    new_df['genres_split'] = new_df['genres'].apply(lambda x: x.split(\",\"))\n",
    "    # mlb = MultiLabelBinarizer()\n",
    "    genere_encoder_df = pd.DataFrame(mlb.transform(new_df['genres_split']))\n",
    "    genere_encoder_df.columns = mlb.classes_.tolist()\n",
    "\n",
    "    # processing on `studio` column\n",
    "    studio_freq_df = pd.DataFrame(new_df['studio'].apply(lambda x: dict_cat_freq[x] if x in dict_cat_freq.keys() else min(dict_cat_freq.values())))\n",
    "    studio_freq_df.columns = ['studio_freq']\n",
    "\n",
    "\n",
    "    processed_cat_df = pd.concat([genere_encoder_df, studio_freq_df, new_df['is_adult']], axis=1)\n",
    "\n",
    "    return processed_cat_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "categorical_process(df_cat).columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 4: Embedding Column Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def listToDF(df, column_name):\n",
    "\n",
    "    new_df = []\n",
    "    for row in df[column_name]:\n",
    "        ls = []\n",
    "        row = eval(row)\n",
    "        for each in row:\n",
    "            ls.append(each)\n",
    "        new_df.append(ls)\n",
    "\n",
    "    new_df = pd.DataFrame(new_df)\n",
    "\n",
    "    return new_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def embedding_process(df):\n",
    "    new_df = df.copy()\n",
    "\n",
    "    # image embeddings\n",
    "    img_emb_df = listToDF(new_df, 'img_embeddings')\n",
    "    text_emb_df = listToDF(new_df, 'text_embeddings')\n",
    "\n",
    "    processed_emb_df = pd.concat([img_emb_df, text_emb_df], axis=1)\n",
    "    return processed_emb_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embedding_process(X1.loc[:, ['img_embeddings', 'text_embeddings']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 5: Combine Everything"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_combine(df_num, df_cat, df_emb):\n",
    "    new_df = pd.concat([df_num, df_cat, df_emb], axis=1)\n",
    "    return new_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_processed = data_combine(df_num, categorical_process(df_cat), df_emb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_processed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 6: Normalization and Standarization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_scaling(df):\n",
    "    \"\"\"\n",
    "    This function will process on the numercial columns.\n",
    "    For `ratings`, we will use normalization\n",
    "    For the other columns, we will use standardization\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_X = df.copy().to_numpy()\n",
    "    # new_df = df.copy()\n",
    "\n",
    "    # df_norm = new_df[\"ratings\"]\n",
    "    # df_stad = new_df.iloc[:, 1:]\n",
    "    scaler_norm = MinMaxScaler().fit(new_X[:, 0].reshape([-1, 1]))\n",
    "    scaler_stad = StandardScaler().fit(new_X[:, 1:5])\n",
    "    new_X[:, 0] = scaler_norm.transform(new_X[:, 0].reshape([-1, 1])).ravel()\n",
    "    new_X[:, 1:5] = scaler_stad.transform(new_X[:, 1:5])\n",
    "\n",
    "    return new_X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_scaling(df_processed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Construct Data Engineering Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def DataEngineering(df):\n",
    "    df_cleaned = data_cleaning_process(df)\n",
    "    df_num, df_cat, df_emb = data_type_split(df_cleaned)\n",
    "    df_cat_processed = categorical_process(df_cat)\n",
    "    df_emb_processed = embedding_process(df_emb)\n",
    "    df_processed = data_combine(df_num, df_cat_processed, df_emb_processed)\n",
    "    X_ready = data_scaling(df_processed)\n",
    "\n",
    "    return X_ready"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocess_transformer = FunctionTransformer(DataEngineering)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p1 = Pipeline([\n",
    "    ('Preprocessor', preprocess_transformer)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X1_pre = p1.fit_transform(X1)\n",
    "X1_pre[:5, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Feature Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 Give the column names to the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def renamingDataset(X):\n",
    "    new_X = X.copy()\n",
    "    new_df = pd.DataFrame(new_X)\n",
    "    num_col_names = ['ratings', 'n_votes', 'production_year', 'runtime', 'release_year']\n",
    "    cat_col_names = ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime',\n",
    "       'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'Game-Show',\n",
    "       'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News', 'Others',\n",
    "       'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Thriller', 'War',\n",
    "       'Western', 'studio_freq', 'is_adult']\n",
    "    img_emb_names = []\n",
    "    for i in range(2048):\n",
    "        img_emb_names.append(\"img_emb_\" + str(i))\n",
    "\n",
    "    text_emb_names = []\n",
    "    for i in range(768):\n",
    "        text_emb_names.append(\"text_emb_\" + str(i))\n",
    "\n",
    "    all_col_names = num_col_names + cat_col_names + img_emb_names + text_emb_names\n",
    "\n",
    "    new_df.columns = all_col_names\n",
    "\n",
    "    return new_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "renamed_df_ready = renamingDataset(X1_pre)\n",
    "renamed_df_ready.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def divideDataset(df):\n",
    "    new_df = df.copy()\n",
    "\n",
    "    non_emb_df = new_df.iloc[:, :34]\n",
    "    img_emb_df = new_df.iloc[:, 34:2082]\n",
    "    text_emb_df = new_df.iloc[:, 2082:]\n",
    "\n",
    "    return non_emb_df, img_emb_df, text_emb_df # pd.dataframe type"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "non_emb_df, img_emb_df, text_emb_df = divideDataset(renamed_df_ready)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 DR on Embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler_emb = MinMaxScaler()\n",
    "emb_df_scaled = scaler_emb.fit_transform(pd.concat([img_emb_df, text_emb_df], axis=1))\n",
    "pca_emb = PCA(n_components=0.9)\n",
    "pca_emb.fit(emb_df_scaled)\n",
    "\n",
    "def DRembeddings(img_emb_df, text_emb_df):\n",
    "\n",
    "    # scale the data to the range between 0 and 1 before using PCA\n",
    "    # scaler_emb = MinMaxScaler()\n",
    "    # img_emb_df_scaled = scaler_emb.fit_transform(img_emb_df)\n",
    "    # text_emb_df_scaled = scaler_emb.fit_transform(text_emb_df)\n",
    "    emb_df_scaled = scaler_emb.fit_transform(pd.concat([img_emb_df, text_emb_df], axis=1))\n",
    "\n",
    "    # pca_emb = PCA(n_components=n_components)\n",
    "    # df_reduced_emb = pd.DataFrame(pca_emb.fit_transform(emb_df_scaled))\n",
    "    df_reduced_emb = pd.DataFrame(pca_emb.transform(emb_df_scaled))\n",
    "\n",
    "    emb_col_names = []\n",
    "    for i in range(df_reduced_emb.shape[1]):\n",
    "        emb_col_names.append(\"emb_\" + str(i))\n",
    "\n",
    "    df_reduced_emb.columns = emb_col_names\n",
    "\n",
    "    return df_reduced_emb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_reduced_emb = DRembeddings(img_emb_df, text_emb_df)\n",
    "df_reduced_emb.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 Feature Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will predict the log(1 + Y1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    The forward feature selection takes a bit time, so we saved the feature selection reulst into a file using torch\n",
    "\"\"\"\n",
    "# np.random.seed(42)\n",
    "# rfr = RandomForestRegressor(n_jobs=-1)\n",
    "# sfs_34features = SequentialFeatureSelector(\n",
    "#     rfr,\n",
    "#     k_features=34,\n",
    "#     forward=True,\n",
    "#     floating=False,\n",
    "#     verbose=2,\n",
    "#     scoring='r2',\n",
    "#     cv=10,\n",
    "# ).fit(non_emb_df, np.log(1 + Y1))\n",
    "# if Path('../models').exists():\n",
    "#     torch.save(\"../models/foward_feature_selection_20features\")\n",
    "# else:\n",
    "#     Path('../model').mkdir(parents=True, exist_ok=True)\n",
    "#     torch.save(\"../models/foward_feature_selection_20features\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the feature selection result\n",
    "sfs_34 = torch.load(\"../models/foward_feature_selection_20features\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(sfs_34.get_metric_dict()).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig1 = plot_sfs(sfs_34.get_metric_dict(), kind='std_dev')\n",
    "plt.title('Sequential Forward Selection (w. StdDev)')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sfs_34.k_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sfs_34.k_feature_idx_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_selected = list(sfs_34.k_feature_names_)\n",
    "non_emb_df_selected = non_emb_df[features_selected]\n",
    "non_emb_df_selected.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4 Combine selected non_emb with reduced emb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def combineNonReducedEmb(non_emb_df_selected, reduced_emb_df):\n",
    "    DR_df = pd.concat([non_emb_df_selected, reduced_emb_df], axis=1)\n",
    "    return DR_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DR_df = combineNonReducedEmb(non_emb_df_selected, df_reduced_emb)\n",
    "DR_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Construct Feature Selection Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def FeatureSelection(X):\n",
    "    renamed_df_ready = renamingDataset(X)\n",
    "    non_emb_df, img_emb_df, text_emb_df = divideDataset(renamed_df_ready)\n",
    "    reduced_emb_df = DRembeddings(img_emb_df, text_emb_df)\n",
    "    non_emb_df_selected = non_emb_df[features_selected]\n",
    "    DR_df = combineNonReducedEmb(non_emb_df_selected, reduced_emb_df)\n",
    "\n",
    "    return DR_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_selection_transformer = FunctionTransformer(FeatureSelection)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p2 = Pipeline([\n",
    "    ('Preprocessor', preprocess_transformer),\n",
    "    ('FeatureSelection', feature_selection_transformer),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X1_ready = p2.fit_transform(X1)\n",
    "X1_ready.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
